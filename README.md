# YouTube 直播 AI 目标追踪应用


一份实时、交互式的 AI 目标检测与追踪 Web 应用，专为 YouTube 直播设计。它能在用户的浏览器中实时识别和追踪视频流中的多个目标。

---

## 📖 项目概述

本项目的核心目标是构建一个能够对 YouTube 直播流进行实时 AI 分析的工具。它采用了一种独特的“云端大脑、前端眼睛”架构：

*   **云端大脑 (Backend)**：在服务器端，一个轻量级的 Python Flask 应用负责处理与 YouTube 的通信。它巧妙地绕过 YouTube 的反爬虫机制，获取到最原始的直播流地址。
*   **前端眼睛 (Frontend)**：在用户的浏览器中，JavaScript 负责所有的“智能”工作。它利用 TensorFlow.js 加载 COCO-SSD 模型进行目标检测，并运行一个自定义的追踪算法，对用户选定的目标进行持续追踪。

用户可以通过简单的点击来“锁定”视频中的任何目标，应用会为其分配一个追踪器，并在侧边栏显示其信息，实现了高度交互和用户自定义的监控体验。

## 🚀 快速上手

你可以在任何支持 Python 和现代浏览器的 Linux/macOS 环境中运行此应用。

### 1. 环境准备

确保你的系统中已安装 **Python 3.8+** 和 `pip`。

### 2. 克隆仓库

```bash
git clone https://github.com/albertjlguo/LockNT2.git
cd LockNT2
```

### 3. 安装依赖

项目使用 `uv` 进行包管理。推荐使用 `uv` 来创建虚拟环境并安装依赖。

```bash
# 安装 uv (如果尚未安装)
pip install uv

# 创建并激活虚拟环境
uv venv
source .venv/bin/activate

# 安装依赖
uv pip install -r requirements.txt
```

### 4. 运行应用

一切就绪后，运行主程序：

```bash
python main.py
```

服务器将在 `0.0.0.0:5000` 启动。你会在终端看到类似以下的输出：

```
* Serving Flask app 'app'
* Running on http://127.0.0.1:5000
```

### 5. 访问应用

打开你的浏览器，访问 `http://127.0.0.1:5000`。输入一个 YouTube 直播的 URL，点击“开始推流”，即可开始使用。

## 🏛️ 架构与设计阐述

### 关键技术决策：为何将 AI 计算放在前端？

本项目最核心的架构决策是将 AI 计算（目标检测与追踪）完全放在客户端（浏览器）执行。这是一个经过深思熟虑的权衡：

*   **挑战**：实时视频 AI 分析通常是计算密集型任务，对服务器资源要求很高，尤其是当需要支持多用户时，成本会急剧上升。
*   **解决方案**：利用现代浏览器日益强大的计算能力和 WebGL 加速，将 AI 模型（TensorFlow.js）和算法逻辑直接分发给用户。服务器只扮演一个“视频流中继”的角色。
*   **优势**：
    1.  **极低的服务器成本**：服务器无需昂贵的 GPU，只需处理网络 I/O。
    2.  **无限的水平扩展能力**：每增加一个用户，只是增加了一个网络连接，计算压力由用户自己承担。
    3.  **数据隐私**：视频内容和分析结果保留在用户本地，不经过服务器存储。
*   **劣势**：
    1.  **对用户设备有要求**：低性能设备可能会体验不佳。
    2.  **模型大小受限**：为了快速加载，只能使用轻量级的模型，精度可能不如服务器端的大模型。

### 直播流获取方案：一个健壮的后端代理

这是项目的首要工程挑战。直接在前端通过 JavaScript 获取并渲染第三方直播流（如 YouTube）会面临巨大的挑战，主要是浏览器的 **同源策略 (Same-Origin Policy)** 和 **跨域资源共享 (CORS)** 限制。浏览器会阻止脚本直接请求来自不同域的视频数据。

为了解决这个难题，我们设计了一个健壮的后端代理方案：

*   **后端作为代理层**：前端不直接与 YouTube 通信。相反，它将 YouTube 直播 URL 发送到我们的后端服务器。
*   **强大的流解析工具**：后端利用 `yt-dlp` 这个强大的命令行工具。`yt-dlp` 封装了与 YouTube 复杂内部 API 通信的所有细节，能够可靠地解析出最底层的视频流媒体地址（通常是 `.m3u8` 格式）。
*   **视频流的“转手”**：获取到流地址后，后端使用 OpenCV 的 `VideoCapture` 像播放器一样打开这个流，并逐帧读取图像。
*   **统一的视频接口**：最后，后端将这些图像编码并通过一个自己的 API 接口（例如 `/video_feed`）提供给前端。对于前端来说，它只是在从一个同源的、简单的接口获取图像，完全绕过了跨域的复杂性。

通过这种方式，所有与 YouTube 的复杂交互都被隔离在后端，为前端提供了一个干净、稳定、无跨域问题的视频源。

## 🧠 对象追踪算法：一个轻量级的多目标追踪器

为了在浏览器中高效运行，我们设计并实现了一个自定义的轻量级多目标追踪器 (`tracker.js`)。它不依赖任何重型库，核心思路结合了**运动预测**和**外观匹配**。

### 设计思路

当用户点击一个检测框“锁定”目标后，追踪器会为该目标创建一个生命周期状态，包含以下核心步骤：

1.  **初始化 (Initialization)**：
    *   记录目标的初始位置、大小。
    *   提取目标的**外观特征**：计算其 HSV 颜色空间的颜色直方图。HSV 对光照变化不敏感，比 RGB 更适合做特征描述。

2.  **预测 (Prediction)**：
    *   在下一帧到来之前，使用一个简单的**线性运动模型**（或称 Alpha-Beta 滤波器）预测目标可能出现的位置。这假设目标在短时间内会保持匀速运动。
    *   `predicted_position = last_position + velocity`

3.  **匹配 (Association)**：
    *   在新一帧的所有检测结果中，寻找与预测位置最匹配的候选框。匹配的依据是**代价函数 (Cost Function)**，综合了两种度量：
        *   **运动代价**：预测位置与候选框位置的距离（欧氏距离）。
        *   **外观代价**：初始外观特征（HSV 直方图）与候选框外观特征的相似度（巴氏距离）。
    *   `cost = w1 * motion_cost + w2 * appearance_cost`
    *   选择总代价最低且低于某个阈值的候选框作为最佳匹配。

### 目标丢失与遮挡策略

现实场景中，目标丢失和遮挡是常见问题。我们的追踪器设计了相应的处理机制：

*   **丢失容忍 (Miss Tolerance)**：如果连续几帧（例如 `maxMisses = 5`）都没有找到任何匹配的候选框，追踪器会进入“丢失”状态。在此期间，它会继续根据最后的速度进行预测，尝试在目标重新出现时找回它。
*   **状态门控 (Gating)**：当目标被标记为“丢失”时，其外观特征的权重会降低，更多地依赖运动预测。如果一个目标丢失时间过长，超过了容忍上限，追踪器会将其彻底删除，以防无限期地追踪一个不再存在的物体。
*   **外观更新**：为了适应目标外观的缓慢变化（如光照改变），追踪器的外观模型会以一个较小的学习率，用最新匹配到的目标外观来更新初始特征，实现自适应调整。

通过以上设计，这个轻量级的追踪器在保证浏览器性能的同时，实现了相当鲁棒的追踪效果。
